{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "from matplotlib.pyplot import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils import data\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "folder = \"../data/processed_data\"\n",
    "positive_dataset = []\n",
    "negative_dataset = []\n",
    "\n",
    "positive_reshaped_dataset = []\n",
    "negative_reshaped_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_training_data(folder):\n",
    "    for f in os.listdir(folder):\n",
    "        if len(f) > 14 and f[-14:] == \"top-copper.png\":\n",
    "            orig_img = imread(os.path.join(folder,f))\n",
    "            orig_img = np.array(orig_img)\n",
    "            positive_dataset.append(orig_img)\n",
    "            resized_img = cv2.resize(orig_img, dsize=(240, 240), interpolation=cv2.INTER_CUBIC)\n",
    "            positive_reshaped_dataset.append(resized_img)\n",
    "        if len(f) > 17 and f[-17:] == \"bottom-copper.png\":\n",
    "            orig_img = imread(os.path.join(folder,f))\n",
    "            orig_img = np.array(orig_img)\n",
    "            negative_dataset.append(orig_img)\n",
    "            resized_img = cv2.resize(orig_img, dsize=(240, 240), interpolation=cv2.INTER_CUBIC)\n",
    "            negative_reshaped_dataset.append(resized_img)\n",
    "load_ground_training_data(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb14040ed0cc469dac3dc7b5040e3b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1] loss: 0.528\n",
      "1\n",
      "[2] loss: 0.457\n",
      "2\n",
      "[3] loss: 0.382\n",
      "3\n",
      "[4] loss: 0.410\n",
      "4\n",
      "[5] loss: 0.425\n",
      "5\n",
      "[6] loss: 0.612\n",
      "6\n",
      "[7] loss: 0.370\n",
      "7\n",
      "[8] loss: 0.284\n",
      "8\n",
      "[9] loss: 0.218\n",
      "9\n",
      "[10] loss: 0.177\n",
      "10\n",
      "[11] loss: 0.146\n",
      "11\n",
      "[12] loss: 0.034\n",
      "12\n",
      "[13] loss: 0.353\n",
      "13\n",
      "[14] loss: 0.087\n",
      "14\n",
      "[15] loss: 0.065\n",
      "15\n",
      "[16] loss: 0.024\n",
      "16\n",
      "[17] loss: 0.026\n",
      "17\n",
      "[18] loss: 0.013\n",
      "18\n",
      "[19] loss: 0.013\n",
      "19\n",
      "[20] loss: 0.011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GroundPlaneNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GroundPlaneNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 1, 5, stride=2, dilation=2)\n",
    "        self.fc1 = nn.Linear(116*116, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(-1, 116*116)\n",
    "        x = self.fc1(x)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class GroundPlaneDataset(data.Dataset):\n",
    "    def __len__(self):\n",
    "        return len(positive_reshaped_dataset) + len(negative_reshaped_dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if index >= len(positive_reshaped_dataset):\n",
    "            img = ToTensor()(negative_reshaped_dataset[index-len(positive_reshaped_dataset)])\n",
    "            gt = torch.Tensor(np.asarray([0])).unsqueeze(0)\n",
    "        else:\n",
    "            img = ToTensor()(positive_reshaped_dataset[index])\n",
    "            gt = torch.Tensor(np.asarray([1])).unsqueeze(0)\n",
    "        return img,gt\n",
    "        \n",
    "        \n",
    "def train():\n",
    "    train_dataset = GroundPlaneDataset()\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=4, \n",
    "                                       shuffle=True, num_workers=4, \n",
    "                                       drop_last=True)\n",
    "    EPOCHS = 20\n",
    "\n",
    "    import torch.optim as optim\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Tune the learning rate.\n",
    "    # See whether the momentum is useful or not\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):  # loop over the dataset multiple times\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(train_dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, gt = batch\n",
    "\n",
    "            inputs = inputs\n",
    "            gt = gt\n",
    "            \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, gt.squeeze(0).squeeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Normalizing the loss by the total number of train batches\n",
    "        running_loss/=len(train_dataloader)\n",
    "        print('[%d] loss: %.3f' %\n",
    "            (epoch + 1, running_loss))\n",
    "\n",
    "        \n",
    "model = GroundPlaneNet()\n",
    "train()\n",
    "torch.save(model.state_dict(), \"GroundDetectionModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
